% !TEX encoding = UTF-8
% !TEX TS-program = pdflatex
% !TEX root = ../../tesi.tex
\subsubsection{Apache JMeter}
Apache JMeter è stato sviluppato da Apache e presenta la sua prima versione nel 1998. È considerato il leader degli strumenti di test di carico nel mercato open source: La sua longevità vanta una vastissima community attiva e il prodotto offre un esteso parco di funzionalità.\\ 
E’ scritto in Java richiedendo una certa familiarità con la JVM e ha una curva di apprendimento piuttosto ripida: l’interfaccia risulta molto complessa e ci vuole del tempo per prendere familiarità con tutte le funzionalità offerte dal prodotto.\\
Utilizza un \gls{dsl} di XML ed è sconsigliato scrivere i test a mano, rendendo molto difficile la modularità e il versionamento.\\
I test vengono eseguiti via \gls{cli} e sono molto performanti, il software riesce a generare molti utenti concorrenti e supporta l’esecuzione distribuita tramite architettura master/slave sfruttando la tecnologia Java RMI e rendendo possibile la generazione di carichi molto elevati. \\
Permette di generare gli scnari di test registrando la navigazione utente sul browser ed esiste il plugin  ufficiale per Jenkins.\\
Il report generato (in formato HTML) è molto completo ed è possibile esportare i dati grezzi in formato XML o CSV, permettendo di creare documenti in modo personalizzato. \\
È IL prodotto per l’enterprise: maturo, vivo, versatile e performante, oltre ad essere completamente gratuito. L'unica pecca si riscontra nella stesura dei test: l'interfaccia grafica può rendere macchinosa la fase di sviluppo, rendendo molto difficile il loro versionamento e/o la loro modifica al di fuori dell'ambiente integrato.
\subsubsection{Gatling}
Attivo da circa 5 anni, Gatling può essere considerato come una versione più moderna di Jmeter: entrambi girano sulla JVM (nonostante Gatling sfrutti Scala) e offrono prestazioni molto simili. Tuttavia Gatling converge più verso il mondo degli sviluppatori che a quello dei tester: l'espressivo e semplice \gls{dsl} di Scala con cui si scrivono gli scenari di test ne permette il versionamento e la modularità, favorendone l'inserimento in un \gls{version-control}. \\
Come JMeter, permette la generazione dei test registrando la navigazione del browser ma non offre lo stesso parco di protocolli del software di Apache, limitandosi a HTTP, JDBC e JMS. \\
Nasce come versione free ma permette l’upgrade alla versione enterprise che offre un'interfaccia grafica per controllare l'esecuzione dei test e migliora le metriche rilevate, oltre a facilitare l’integrazione con le piattaforme di Cloud. Il punto forte della versione enterprise è nell'esecuzione dei test su infrastruttura distribuita, che nella versione free è disponibile solo tramite script personalizzati. \\
Il report generato viene fornito in formato HTML permettendo di personalizzarne i grafico, i dati grezzi purtroppo sono salvati in un formato non documentato e l'azienda ne sconsiglia l'utilizzo per generare documenti personalizzati. Tuttavia esistono librerie che ne permettono la conversione in CSV in modo da facilitarne l'utilizzo.\\
Esiste il plugin ufficiale per Jenkins e tramite il \gls{dsl} è possibile progettare dei criteri che marchino il test come riuscito o fallito, rendendolo ideale per i sistemi di \gls{integrazione-continua}.\\
Anche Gatling è un prodotto enterprise ready e compensa la minore completezza rispetto a JMeter con la modernità del suo utilizzo.
\subsubsection{Locust}
Locust è un progetto nato nel 2011, scritto da sviluppatori per sviluppatori: utilizza il linguaggio di programmazione Python e tramite l'ottima documentazione è possibile estenderne le funzionalità con del codice personalizzato. \\
Questa caratteristica si rivela però un arma a doppio taglio: \gls{out-of-the-box} il software non offre molte funzionalità, supportando il solo protocollo HTTP e generando report piuttosto scarni.\\
Lo strumento permette due modalità di utilizzo: via \gls{cli} e via browser. La prima è ideale per i sistemi di \gls{integrazione-continua} mentre la seconda è ottima per monitorare lo svolgimento del test grazie a dei grafici che vengono generati in tempo reale. \\
I risultati finali possono essere esportati in formato CSV o essere raccolti direttamente dalla console di esecuzione in caso di utilizzo via \gls{cli}.
Gli scenari di test vengono scritti completamente in Python garantendone la modularità e il versionamento, oltre ad una discreta flessibilità. Purtroppo il prodotto non presenta funzionalità di browser recording, rendendo oneroso lo sviluppo di scenari complessi.\\
Il software consuma poca memoria durante la sua esecuzione ma per sfruttare al 100\% la sua potenza è necessario superare una ripida curva d'apprendimento: pur supportando l'esecuzione dei test su infrastruttura distribuita, errate configurazioni possono fare da collo di bottiglia alle prestazioni, rendendo poco utile lo strumento. Per capire quest'ultima constatazione è sufficiente guardare i benchmark di Blazemeter e Loadimpact citati nella bibliografia: la differenza di prestazioni è abissale e nella sezione commenti di Loadimpact un utente spiega il perché. 
Non esistono plugin ufficiali per jenkins ma grazie all'architettura del prodotto non è difficile svilupparne uno tramite Python. \\
Sostanzialmente Locust è un prodotto focalizzato molto per gli sviluppatori e a causa di questo si porta con sé l’onere di sviluppare: con tempo e volontà è sicuramente possibile implementare il test di carico perfetto per la propria azienda, ma sono in poche a poter fare questo sacrificio.
Allo stato attuale Locust è adeguato per testare sistemi poco complessi ma magari, con l’espansione della community, in un futuro sarà possibile utilizzarlo anche per applicazioni enterprise con più sicurezza e meno personalizzazioni.
\subsubsection{The Grinder}
The grinder è un tool di load testing scritto in Java nel 2000. Pare essere un tool completo e performante ma viola il primo requisito della ricerca: l’ultima release ufficiale risale al 2012 mentre l’ultimo commit è del 2015 (la repository si trova su Sourceforge).
Evenutalmente esiste un repository anche su Github che è stato aggiornato di recente ma, osservando le statistiche, è poco diffuso a non ha molti manutentori.
\subsubsection{K6}
K6 è un tool di recentissima fattura pubblicato da Loadimpact per la prima volta nel 2017, autodefinendosi “come dovrebbe essere un tool di load testing nel 2017”. \\
Gli scenari di test sono scritti in Javascript ed è possibile utilizzare tutte le librerie offerte dal linguaggio, oltre a quella specifica del software K6, rendendo il migliore per il lato modularità e versionamento. Il prodotto è rivolto principalmente agli sviluppatori e l’esecuzione dei test via \gls{cli} unito all'espressività di Javascript lo rende facilmente integrabile in ambienti di \gls{integrazione-continua} come Jenkins. \\
Il report vengono generati direttamente sulla \gls{cli} ma è minimale e poco esaustivo, questo è voluto in quanto il prodotto sembra essere parte di una strategia che invogli l’utente alla sottoscrizione di abbonamenti con Loadimpact che offre un più completo sistema di analisi (è presente infatti una modalità esecuzione via \gls{cli} direttamente sui server di Loadimpact). \\
Nonostante ciò è possibile esportare i dati in formato JSON che contiene informazioni molto più dettagliate rispetto al report standard, inoltre è presente in modo nativo l'integrazione con diversi software di reportistica, come InfluxDB e Grafana, permettendo di generare report molto più completi.\\
Le performance su un singolo computer sono simili a quelle di Gatling ma al momento non è possibile eseguire i test in modalità distribuita (al netto di orchestrazioni personalizzate), tuttavia la funzionalità è prevista nella roadmap per fine anno (anche se non ci sono certezze da questo punto di vista). \\
Piccola nota: molta della letteratura trovata sul tema è fornita da Loadimpact, quindi le valutazioni su questo strumento potrebbero essere un po’ di parte. Tuttavia anche altre fonti sembrano suggerire la validità di questo software.
\subsubsection{Taurus}
Taurus è un software prodotto da Blazemeter nel 2015 ed è da considerarsi più come un'orchestratore di strumenti di test di carico che un load testing tool stesso. È stato pensato per risolvere i problemi di automazione e/o \gls{integrazione-continua} di molti dei tool di test di carico presenti sul mercato offrendo la libertà di scelta su quale di questi usare.\\
Taurus è infatti capace di eseguire file di JMeter, Gatling, Tsung, The Grinder e altri tool di test di carico fino ad arrivare alla simulazione effettiva di un browser tramite Selenium (oltre a supportare tool di test funzionale come Robot Framework), lasciando come unico onere la configurazione tipo di carico da generare tramite comodi file YAML. \\
Non è presente letteratura sulle sue performance, tuttavia è facile immaginare come queste non siano prevedibili: dipendono dallo strumento utilizzato a cui vanno aggiunti i costi di orchestrazione. \\
Come funzionalità non ha eguali ma essendo sviluppato dal team di Blazemeter per il loro servizio di Cloud non può offrire tutte queste funzionalità gratuitamente: la reportistica infatti è minimale, nonostante quella in tempo reale della console sia molto valida, e per ottenere risultati persistenti è necessario abbonarsi ai servizi di Blazemeter, che nella versione free permettono di salvare i report, visualizzandoli tramite il servizio, per un massimo 7 giorni.
Eventualmente Taurus produce una cartella con tutti i log generati durante l’esecuzione, questi però non sono a formato fisso in quanto dipendono dai tool utilizzati per il testing (JMeter, Gatling, Selenium, etc.). Volendo è quindi possibile generare reportistica esaustiva e persistete ma necessita di orchestrazioni personalizzate. \\
L'esecuzione su infrastruttura distribuita dipende dal tool che si usa tramite Taurus oppure è garantita con tutti i tipi di test utilizzando i servizi di Blazemeter a pagamento. \\
Taurus si presenta come un software molto competente e valido, purtroppo le limitazioni della versione free non ne permettono l'utilizzo in ambiente enterprise e i costi del servizio a pagamento non sono trascurabili.
\subsubsection{Vegeta}
Vegeta è un tool di test di carico presentato nel 2014 da un singolo sviluppatore, è un tool eseguito via \gls{cli} che nonostante sia semplice da apprendere risulta un po' intricata come usabilità. \\
Le performance sono buone, leggermente superiori a quelle di gatling, ed è possibile creare tanti carichi tramite infrastruttura distribuita anche se la funzionalità non è inclusa nativamente nel software ma necessita di orchestrazioni esterne per essere funzionante. \\
Vegeta offre anche la possibilità di scrivere ed eseguire i test tramite una libreria scritta in GO, permettendone la modularità e il versionamento. \\
Tuttavia la semplicità d’utilizzo di Vegeta giunge ad un compromesso con le poche funzionalità messe a disposizione: non è possibile infatti descrivere scenari complessi: la definizione degli stessi si limita a selezionare in round-robin gli url indicati senza poter simulare un vero e proprio comportamento dell'utente. \\
Inoltre la configurazione di vegeta permette poco controllo sulla distribuzione del carico: il tool infatti permette unicamente di indicare la quantità di richieste per secondo desiderate (caratteristica che in pochi altri tool riescono ad offrire) lasciando libertà al tool di gestire le risorse della macchina per raggiungere il ratio indicato. Questa caratteristica non sopperisce però alla mancanza di ramp-up (anche se possibile realizzarla via bash scripting) e alla possibilità di controllare attivamente le risorse del sistema (come il numero massimo di thread). \\
In definitiva, Vegeta è un buon per testare singoli endpoint in modo controllato e imbastire sistemi di CI più complessi grazie alla versatilità della libreria in Go e la facilità d’integrazione con tool di terze parti, tuttavia per scenari più complessi e configurazioni più avanzate guardare altrove.
\subsubsection{Wrk}
Wrk è un tool amatoriale pubblicato per la prima volta nel 2012.
Onestamente non c’è troppo da dire su Wrk, partendo dalla documentazione ufficiale praticamente inesistente, le funzionalità offerte da Wrk non offrono tanto spazio di manovra.
E’ il tool più potente per quanto riguarda il throughput grezzo su una singola macchina ed è l’unico strumento in grado di utilizzare al 100\% le risorse della CPU in condizioni ottimali: target server immediato nella risposta e basso peso, in byte, della richiesta invat. Con scenari di test più complessi inoltre il tool perde accuratezza nelle misurazioni dei tempi di riposta, diventando poco utile. \\
Non offre la possibilità di distribuire l’esecuzione dei test su più macchine e in rete non si trovano argomenti per farlo a mano, suggerendo che questo non è il suo caso d'uso.
La \gls{cli} è comoda e permette di integrare scenari più complessi utilizzando il linguaggio di scripting Lua che permette anche di convertire i risultati nel formato di output desiderato.
I report sono poco esaustivi, \gls{out-of-the-box} è offerta solo la visualizzazione in \gls{cli} ma le metriche raccolte sono generiche e non permettono un’analisi dettagliata.\\
Non esiste letteratura per quanto riguarda eventuali integrazioni in \gls{integrazione-continua}, suggerendo anche qui che per l’automazione non è il miglior tool, a meno di personalizzazioni in Lua.
\subsubsection{Apachebench}
Come per Wrk, anche Apache Bench (ab) non ha molto di raccontare, sviluppato per testare le performance del webserver apache, svolge un ottimo lavoro nel colpire un singolo URL e riportarne i risultati.\\
Data la sua maturità e ottimizzazione è in grado di generare un grosso carico sfruttando unicamente un singolo core della CPU ma oltre non va: non supporta l’esecuzione distribuita e non sfrutta CPU multicore. \\
Genera un carico dimezzato rispetto a Wrk ma offre un report ed un’accuratezza migliore, nonostante non sia possibile esportare il report in formati universali di default, richiedendo un'elaborazione ad hoc in caso si voglia esportare i dati dalla \gls{cli}.
L'esecuzione avviene via \gls{cli} e permette di configurare comodamente diversi parametri.\\
Ottimo per test semplici e feedback immediati ma non adeguato per integrazione in \gls{integrazione-continua} e stesura di scenari complessi.
\subsubsection{Tsung}
%TODO -> citazione a loadimpact: "le funzionalità ci sono, l'usabilità un po' meno"
Nato nel 2001 come successore di Tsunami IDX,Tsung è uno strumento di test di carico multiprotocollo scritto in Erlang, robusto e maturo: tra le sue funzionalità prevede la registrazione del browser e il supporto \gls{out-of-the-box} per l'esecuzione dei test in modalità distribuita.\\
Gli scenari di test vengono scritti in XML ma a differenza di JMeter non offre un'interfaccia grafica per aiutare la scrittura degli scenari, nonostante il \gls{dsl} di Tsung sia molto più chiaro e facile da apprendere rispetto a quello di JMeter. Eventualmente possono essere scritti scenari più complessi con l'ausilio di Erlang. \\
Il report generato è molto esaustivo ed oltre ai risultati statistici finali offre la possibilità di monitorare le statistiche d'esecuzione in tempo reale tramite un'intuitiva interfaccia web. I dati finali possono essere esportati in JSON e la loro struttura è ben documentata in modo da poter esser facilmente consumati da altre piattaforme di reportistica.\\
Tsung è sicuramente un prodotto pronto per l'enterprise ma è accompagnato da due maggiori inconvenienti: l’usabilità e la predisposizione all’integrazione continua. \\
Gli sviluppatori infatti sono avvezzi a "programmare" in XML che, pur presentando un \gls{dsl} chiaro ed intuitivo, non offre la stessa espressività e flessibilità dei linguaggi di scripting. Inoltre, pur essendo disposto al versionamento, XML è più difficile da modularizzare rispetto ad un normale linguaggio di programmazione.\\
Per quanto riguarda l'\gls{integrazione-continua}, Tsung non presenta plugin ufficiali e la community non offre soluzioni a riguardo, rendendo eventuali integrazioni completamente a carico dell'utente.\\
In definitiva, Tsung è un ottimo prodotto: robusto, maturo e versatile, avente l'unica pecca di presentare un design non al passo con le metodologie di sviluppo software moderne	. 
\subsubsection{Artillery}
Artillery è un tool di test di carico nato da sviluppatori per sviluppatori, è sviluppato in Javascript ed è orientato verso le infrastrutture di \gls{integrazione-continua} proponendo un sistema per bollare il test come riuscito o fallito al termine della sua esecuzione. \\
È possibile configurare il carico e gli scenari di test tramite YAML (o JSON) che offrono la possibilità di integrare codice Javascript.
E’ estensibile tramite \gls{plugin} (la community ne offre già diversi) e offre la possibilità di testare non solo HTTP ma anche WebSocket e Socket.io, suggerendo una propensione per l’ambiente Javascript da parte degli sviluppatori. \\
I report prodotti sono relativi all’analisi statistica finale e vengono forniti in formato HTML ma è possibile esportare i report in CSV o integrarsi database tramite integrazioni via \gls{plugin}. \\
Le prestazioni non sono ottimali: il tool non riesce a generare un grande carico e non è prevista una modalità di esecuzione distribuita se non acquistando la versione Enterprise che grazie all’integrazione con AWS riesce a distribuire l’esecuzione su più macchine migliorandone le performance. \\
Inoltre il software non riesce a sfruttare le CPU multicore anche se questa funzionalità è prevista nella rilascio della seconda versione del prodotto.
\subsubsection{Siege}
Siege è un software di test di carico scritto prevalentemente in C che si concentra sul protocollo HTTP.\\
Dopo diverse ricerche ho notato come Siege non offra grosse prestazioni con test complessi e che non riesca a simulare grossi carichi senza perdere in accuratezza di misurazione.\\
Considerando l'obiettivo di \textbf{Maturità} della ricerca, la poca accuratezza nella misurazione, valutata come bug strutturale, ha portato all'abbandono dello studio di questo prodotto.
\subsubsection{Bees with machine guns}
Una menzione d’onore è assegnata a Bees with machine guns, pur non essendo aggiornato da più di un anno, questo tool permette di generare grossi carichi in maniera distribuita tramite poche righe di \gls{cli}.\\
Sostanzialmente richiede le credenziali di un account AWS e, tramite una piccola configurazione, imbastisce le macchine EC2 richieste (le crea e installa il software necessario), le utilizza per generare il carico richiesto e poi le spegne, tutto in maniera automatica (è possibile spezzare il processo in 3 step, l’orchestrazione, l’esecuzione e lo spegnimento).\\
Non è un software molto sofisticato, ma per test senza grosse pretese o per l'esecuzione di stress test può risultare una scelta molto efficace,  grazie alla facilità con cui si può generare un grosso traffico d'utenti. 
